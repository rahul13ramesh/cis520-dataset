{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIS520-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J0AF0sJvRixT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul13ramesh/cis520-dataset/blob/master/CIS520_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmR8r-op-R7D",
        "colab_type": "text"
      },
      "source": [
        "# CIS-520 Project -[What's cooking](https://www.kaggle.com/c/whats-cooking-kernels-only)\n",
        "\n",
        "* This notebook looks at the Kaggle contest *What's cooking*. We tackle a supervised and unsupervised learning problem using this dataset\n",
        "* The input features are a collection of words and hence NLP techniques are used to build useful features for the downstream task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNDnjIe2Qy7H",
        "colab_type": "code",
        "outputId": "8f59da72-163e-4a56-c059-13a3a0222462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "!pip install pywaffle\n",
        "!git clone https://github.com/amueller/word_cloud.git\n",
        "!cd word_cloud && pip install ."
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pywaffle in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pywaffle) (3.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pywaffle) (2.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pywaffle) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pywaffle) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pywaffle) (1.17.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pywaffle) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->pywaffle) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->pywaffle) (41.6.0)\n",
            "fatal: destination path 'word_cloud' already exists and is not an empty directory.\n",
            "Processing /content/word_cloud\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from wordcloud==1.6.0.post1+g8217e20) (1.17.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud==1.6.0.post1+g8217e20) (4.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from wordcloud==1.6.0.post1+g8217e20) (3.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->wordcloud==1.6.0.post1+g8217e20) (0.46)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->wordcloud==1.6.0.post1+g8217e20) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->wordcloud==1.6.0.post1+g8217e20) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->wordcloud==1.6.0.post1+g8217e20) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->wordcloud==1.6.0.post1+g8217e20) (2.4.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->wordcloud==1.6.0.post1+g8217e20) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud==1.6.0.post1+g8217e20) (41.6.0)\n",
            "Building wheels for collected packages: wordcloud\n",
            "  Building wheel for wordcloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordcloud: filename=wordcloud-1.6.0.post1+g8217e20-cp36-cp36m-linux_x86_64.whl size=335565 sha256=11c1964ebf805984c8d0ad85592f82ab2c2577c6b56a6241f3e92802c973930c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cx0b5ulz/wheels/c9/9e/fe/b14c026a2af072dcf59543bce68dcdfff8a5362e6bb11242d9\n",
            "Successfully built wordcloud\n",
            "Installing collected packages: wordcloud\n",
            "  Found existing installation: wordcloud 1.6.0.post1+g8217e20\n",
            "    Uninstalling wordcloud-1.6.0.post1+g8217e20:\n",
            "      Successfully uninstalled wordcloud-1.6.0.post1+g8217e20\n",
            "Successfully installed wordcloud-1.6.0.post1+g8217e20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWmY91JiLZ4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import unicodedata\n",
        "import re\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from pywaffle import Waffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3jEKYoZNaHv",
        "colab_type": "code",
        "outputId": "f156840c-9f79-474f-9023-dc56c80f56be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/rahul13ramesh/cis520-dataset/master/test.json\n",
        "!wget https://raw.githubusercontent.com/rahul13ramesh/cis520-dataset/master/train.json"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-01 03:11:07--  https://raw.githubusercontent.com/rahul13ramesh/cis520-dataset/master/test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2844086 (2.7M) [text/plain]\n",
            "Saving to: ‘test.json.1’\n",
            "\n",
            "\rtest.json.1           0%[                    ]       0  --.-KB/s               \rtest.json.1         100%[===================>]   2.71M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2019-12-01 03:11:08 (42.9 MB/s) - ‘test.json.1’ saved [2844086/2844086]\n",
            "\n",
            "--2019-12-01 03:11:09--  https://raw.githubusercontent.com/rahul13ramesh/cis520-dataset/master/train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12415067 (12M) [text/plain]\n",
            "Saving to: ‘train.json.1’\n",
            "\n",
            "train.json.1        100%[===================>]  11.84M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-12-01 03:11:09 (124 MB/s) - ‘train.json.1’ saved [12415067/12415067]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zloB0kDdA1k-",
        "colab_type": "text"
      },
      "source": [
        "# Loading dataset\n",
        "We load the dataset and display a single entry from this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbqhyiANecj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"test.json\", \"r\") as f:\n",
        "    test_data = json.load(f)\n",
        "with open(\"train.json\", \"r\") as f:\n",
        "    train_data = json.load(f)\n",
        "train_data_df = pd.DataFrame(train_data)\n",
        "test_data_df = pd.DataFrame(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1KgSaTuNiGi",
        "colab_type": "code",
        "outputId": "fe777455-e1e7-4182-ab1b-61e3fac558fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'greek',\n",
              " 'id': 10259,\n",
              " 'ingredients': ['romaine lettuce',\n",
              "  'black olives',\n",
              "  'grape tomatoes',\n",
              "  'garlic',\n",
              "  'pepper',\n",
              "  'purple onion',\n",
              "  'seasoning',\n",
              "  'garbanzo beans',\n",
              "  'feta cheese crumbles']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0AF0sJvRixT",
        "colab_type": "text"
      },
      "source": [
        "# Data analysis and Visualization\n",
        "\n",
        "The aim of this analysis is as follows:\n",
        "\n",
        "* Gain an understanding of the dataset, distribution of labels and number of data points. \n",
        "* Look for potentially useful features that can help an classifier achieve higher accuracies.\n",
        "* Look for anamolies in data that need to be handled through data pre-processing and cleaning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIRJbIDABeHq",
        "colab_type": "text"
      },
      "source": [
        "### Preliminary Understanding of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCw2sT6MVBOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_df = pd.DataFrame(train_data)\n",
        "test_data_df = pd.DataFrame(test_data)\n",
        "cuisines = train_data_df[\"cuisine\"].unique()\n",
        "print(\"Data size: \" + str(train_data_df.shape))\n",
        "print(\"Numerb of cuisines: \", str(len(cuisines)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8cwK_MHbY2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_df.groupby(by='cuisine').count().sort_values(by='ingredients',ascending=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bDfxuO9Hu-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data_df.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrZpXP2pHvIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Waffle Plot of data distribution\n",
        "class_data = train_data_df.cuisine.value_counts()\n",
        "class_data = ((class_data)*100) // class_data.values.sum()\n",
        "colors = [plt.cm.Spectral(i/float(len(cuisines))) for i in range(len(cuisines))]\n",
        "np.random.seed(5)\n",
        "np.random.shuffle(colors)\n",
        "\n",
        "plt.figure(\n",
        "    figsize=(10, 12),\n",
        "    FigureClass=Waffle, \n",
        "    rows=6,\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1.05, 1), 'fontsize': 9, 'title':'Class', 'ncol': 2},\n",
        "    values=class_data.values,\n",
        "    labels=list(class_data.index),\n",
        "    colors=colors\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEunsCP9tOZC",
        "colab_type": "text"
      },
      "source": [
        "### Analysis of Recipes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBD_D3AHB2PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get space seperated text of all the ingredients\n",
        "text = ''\n",
        "for i in range(train_data_df.shape[0]):\n",
        "    text = text + \" \" + ' '.join(train_data_df.iloc[i, 2])\n",
        "\n",
        "# Get all ingredients as a list (along with cuisine, and number of ingredients for each ingredient)\n",
        "text_list = []\n",
        "text_list_cuisine = []\n",
        "text_list_num = []\n",
        "for i in range(train_data_df.shape[0]):\n",
        "    text_list = text_list + train_data_df.iloc[i, 2]\n",
        "    len_ing = len(train_data_df.iloc[i, 2])\n",
        "    text_list_cuisine = text_list_cuisine + [train_data_df.iloc[i, 1] for i in range(len_ing)]\n",
        "    text_list_num = text_list_num + [len_ing for i in range(len_ing)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejBivkR-Cqwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ingredients(cuisine_val):\n",
        "    \"\"\"\n",
        "    Get all the ingredients for a particular cuisine\n",
        "    \"\"\"\n",
        "    text = ''\n",
        "    for i in range(train_data_df.shape[0]):\n",
        "        if cuisine_val == train_data_df.iloc[i, 1]:\n",
        "            text = text + \" \" + ' '.join(train_data_df.iloc[i, 2])\n",
        "    return text\n",
        "    \n",
        "def get_num_ingredients(cuisine_val):\n",
        "    \"\"\"\n",
        "    Get the number of ingredients of each recipe for a particular cuisine\n",
        "    \"\"\"\n",
        "    num = []\n",
        "    for i in range(train_data_df.shape[0]):\n",
        "        if cuisine_val == train_data_df.iloc[i, 1]:\n",
        "            num.append(len(train_data_df.iloc[i,2]))\n",
        "    return num\n",
        "\n",
        "def plot_word_cloud(txt, coloc=True):\n",
        "    \"\"\"\n",
        "    Plot the word cloud corresponding to some text\n",
        "    \"\"\"\n",
        "    wordcloud = WordCloud(background_color=\"white\", collocations=coloc).generate(txt)\n",
        "    plt.figure(figsize = (7, 7))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ200dr6HJ8_",
        "colab_type": "text"
      },
      "source": [
        "We first plot word clouds based on the ingredients to understand the nature of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHBF2-EiRhIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot word cloud for entire data\n",
        "plot_word_cloud(text,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ06hVjcIaWh",
        "colab_type": "text"
      },
      "source": [
        "We next look at the word-clouds in a per cuisine granularity. The visualizations show that the key ingredients in a recipes vary significantly with the cuisine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBTcYtmQD9WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuisine_ingredients = {}\n",
        "cuisine_numbers = {}\n",
        "for c in cuisines:\n",
        "    cuisine_ingredients[c] = get_ingredients(c)\n",
        "    cuisine_numbers[c] = get_num_ingredients(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn9wwb-bEVtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_word_cloud(cuisine_ingredients['indian'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzpPZSQTFCQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_word_cloud(cuisine_ingredients['italian'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekuzq5s6FMaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_word_cloud(cuisine_ingredients['mexican'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siDJ_gJTIBUI",
        "colab_type": "text"
      },
      "source": [
        "Next we look use Violin-plots (box plots) to understand how  the number of ingredients varies with cuisine. The plots indicate that this feature can be used a useful feature for a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Ro61SDFnLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuisine_num_array = []\n",
        "cuisine_val = []\n",
        "for c in cuisines:\n",
        "    cuisine_num_array = cuisine_num_array + cuisine_numbers[c]\n",
        "    cuisine_val = cuisine_val + [c for _ in range(len(cuisine_numbers[c]))]\n",
        "cuisine_number_df = pd.DataFrame([cuisine_num_array, cuisine_val]).T\n",
        "cuisine_number_df.columns = [\"Number of Ingredients\", \"Cuisine\"]\n",
        "cuisine_number_df[\"Number of Ingredients\"] = pd.to_numeric(cuisine_number_df[\"Number of Ingredients\"])\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "sns.violinplot(x=\"Cuisine\", y=\"Number of Ingredients\", data=cuisine_number_df)\n",
        "\n",
        "plt.figure(figsize=(18,5))\n",
        "sns.violinplot(x=\"Cuisine\", y=\"Number of Ingredients\", data=cuisine_number_df[cuisine_number_df[\"Number of Ingredients\"] <= 25])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIacPYavemOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "long_ingredients = []\n",
        "small_ingredients1 = []\n",
        "small_ingredients2 = []\n",
        "small_ingredients3 = []\n",
        "for i in range(train_data_df.shape[0]):\n",
        "    ing =  train_data_df.iloc[i, 2]\n",
        "    if len(ing) >= 30:\n",
        "        long_ingredients.append((ing, train_data_df.iloc[i, 1]))\n",
        "    elif len(ing) == 1:\n",
        "        small_ingredients1.append((ing, train_data_df.iloc[i, 1]))\n",
        "    elif len(ing) == 2:\n",
        "        small_ingredients2.append((ing, train_data_df.iloc[i, 1]))\n",
        "    elif len(ing) == 3:\n",
        "        small_ingredients3.append((ing, train_data_df.iloc[i, 1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4ItM-vagPcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of long ingredients: \" + str(len(long_ingredients)))\n",
        "print(\"Number of short ingredients: \" + str(len(small_ingredients1)))\n",
        "print(\"Number of short ingredients: \" + str(len(small_ingredients2)))\n",
        "print(\"Number of short ingredients: \" + str(len(small_ingredients3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abZQCPNsg_16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ingredients1\n",
        "# Remove elements with just 1 ingredients, clearly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKHxh9iLhY27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ingredients2[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v_b6QJ4hZDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ingredients3[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt6F55L0iOSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(long_ingredients[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDCl1b85tqY-",
        "colab_type": "text"
      },
      "source": [
        "### Understanding Individual Ingredient / Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0sS8a_By1F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_analysis = text.lower()\n",
        "# Remove elements\n",
        "rem_elems = [\"lb.\", \"oz.\", \"inch\", \"%\", \"™\", \"®\",  \"€\", \"(\", \")\", \",\"]\n",
        "for e in rem_elems:\n",
        "    text_analysis = text_analysis.replace(e, \" \")\n",
        "text_analysis = text_analysis.replace(\"’\", \"'\")\n",
        "text_analysis = ''.join([i for i in text_analysis if not i.isdigit()])\n",
        "ing_analysis = text_analysis.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HMU3oJ_3pv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_counts = []\n",
        "print(\"Number of Ingredients: \" + str(len(set(ing_analysis))))\n",
        "for x in set(ing_analysis):\n",
        "    word_counts.append((ing_analysis.count(x), x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghpe2UrP5ltC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted(word_counts, reverse=True)[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyB2V3kS6FQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ing_count_df = pd.DataFrame(word_counts)\n",
        "ing_count_df.columns = [\"Count\", \"Ingredient\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5w3YSvY77-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.countplot(data=ing_count_df[ing_count_df.Count <= 30], x=\"Count\")\n",
        "# About 600 entries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS2EF8gfA-u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  sns.violinplot(data=ing_count_df[(ing_count_df[\"Count\"] >= 100)], x=\"Count\", cut=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEDn4DiLtGNN",
        "colab_type": "text"
      },
      "source": [
        "### Understanding character Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_bHh4nSHQz7",
        "colab_type": "text"
      },
      "source": [
        "We now look to get an understanding of the frequency of occurence of words in an ingredient. In particular we would like to look at ingredients with special characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfWpoBn4HWHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(' '.join(sorted(set(text))))\n",
        "# Convert upper case to lower case"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gP3FEY4cp3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "digit_char = []\n",
        "\n",
        "for ing, num, cuisine  in zip(text_list, text_list_num, text_list_cuisine):\n",
        "    if any(char.isdigit() for char in ing):\n",
        "        count += 1\n",
        "        if count <= 10:\n",
        "            print(str(num) + \"\\t\" + cuisine + \"\\t\\t\" + ing)\n",
        "        digit_char.append([num, cuisine, ing])\n",
        "# remove numbers number/number, number%, num.number\n",
        "#  add presense of number as feature?\n",
        "tmp_text = ' '.join([row[2] for row in digit_char])\n",
        "plot_word_cloud(tmp_text, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fclTH0LN7oPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ing, num, cuisine  in zip(text_list, text_list_num, text_list_cuisine):\n",
        "    if \"€\" in ing:\n",
        "        print(str(num) + \"\\t\" + cuisine + \"\\t\\t\" + ing)\n",
        "# remove the pound character, since only one item has character"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvAcoMqg8Hb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "copyright_char = []\n",
        "\n",
        "for ing, num, cuisine  in zip(text_list, text_list_num, text_list_cuisine):\n",
        "    if \"®\" in ing or (\"™\" in ing):\n",
        "        count += 1\n",
        "        if count <= 10:\n",
        "            print(str(num) + \"\\t\" + cuisine + \"\\t\\t\" + ing)\n",
        "        copyright_char.append([num, cuisine, ing])\n",
        "print(len(copyright_char))\n",
        "tmp_text = \"\"\n",
        "for row in copyright_char:\n",
        "    for w in row[2].split():\n",
        "        if (\"®\" in w )or (\"™\" in w):\n",
        "            tmp_text = tmp_text + \" \" + w \n",
        "plot_word_cloud(tmp_text,False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJh2lWWq8wAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count1 = 0\n",
        "count2 = 0\n",
        "spl_char = []\n",
        "\n",
        "for ing, num, cuisine  in zip(text_list, text_list_num, text_list_cuisine):\n",
        "    if (\"!\" in ing) or (\"&\" in ing) or (\"(\" in ing) or (\")\" in ing) or (\"'\" in ing) or (\"%\" in ing):\n",
        "        if count1 <= 5 and ('!' in ing):\n",
        "            count1 += 1\n",
        "            print(str(num) + \"\\t\" + cuisine + \"\\t\\t\" + ing)\n",
        "        spl_char.append([num, cuisine, ing])\n",
        "\n",
        "        if count2 <= 5 and ('&' in ing):\n",
        "            count2 += 1\n",
        "            print(str(num) + \"\\t\" + cuisine + \"\\t\\t\" + ing)\n",
        "        spl_char.append([num, cuisine, ing])\n",
        "\n",
        "tmp_text = \"\"\n",
        "for row in spl_char:\n",
        "    for w in row[2].split():\n",
        "        if (\"!\" in w) or (\"&\" in w) or (\"(\" in w) or (\")\" in w) or (\"'\" in w) or (\"%\" in w):\n",
        "            tmp_text = tmp_text + \" \" + w \n",
        "plot_word_cloud(tmp_text, False)\n",
        "# replace & with and maybe (half & half)\n",
        "# Remove %, (, )\n",
        "# ' occurs for plural\n",
        "\n",
        "#There are some spelling errors for example\n",
        "#believ as seen below\n",
        "# ! occurs for a brand \"I can't Believe ti's Not Butter\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77WD6gB6e_cN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accented_char_set= [\"â\", \"ç\", \"è\", \"é\", \"í\", \"î\", \"ú\", \"’\"]\n",
        "accented_char = []\n",
        "count1 = 0\n",
        "count2 = 0\n",
        "\n",
        "for ing, num, cuisine  in zip(text_list, text_list_num, text_list_cuisine):\n",
        "    if 1 in [c in ing for c in accented_char_set]:\n",
        "        if count1 <= 5 and '’' in ing:\n",
        "            count1 += 1\n",
        "            print(str(num) + \"\\t\" + cuisine + \"\\t\\t\" + ing)\n",
        "        elif count2 <= 5:\n",
        "            count2 += 1\n",
        "            print(str(num) + \"\\t\" + cuisine + \"\\t\\t\" + ing)\n",
        "        accented_char.append([num, cuisine, ing])\n",
        "    \n",
        "tmp_text = \"\"\n",
        "for row in accented_char:\n",
        "    for w in row[2].split():\n",
        "        if 1 in [c in w for c in accented_char_set]:\n",
        "            tmp_text = tmp_text + \" \" + w \n",
        "plot_word_cloud(tmp_text, False)\n",
        "# '’' Replace with apostrophe '"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHoZfIohurv2",
        "colab_type": "text"
      },
      "source": [
        "# Creating Features / Dataset Variants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlrn032qvnZh",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/rejasupotaro/what-are-ingredients\n",
        "\n",
        "* Make Upper case to lower case\n",
        "* Remove elements with 1 ingredient\n",
        "* Add feature for special characters â ç è é í î ú \n",
        "* Remove lb. inch oz.\n",
        "* Add feature for:  ™ ® \n",
        "* Add feature for: !     (! used for a particular brand)\n",
        "* Add feature for: Numbers/percentages\n",
        "* Remove symbol: € ™ ( ) ® . - %\n",
        "* Change ’ with ' (first one is a special character)\n",
        "* Replace \"&\" with and  or space(not sure about this)\n",
        "* Remove all numbers\n",
        "* Remove all ,\n",
        "* Add feature if ™ ® \n",
        "* If there are many ingredients, maybe pick a subset of ingredients as features?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD9PPG6BuoQs",
        "colab_type": "text"
      },
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vreuxhhiLeg6",
        "colab_type": "text"
      },
      "source": [
        "* Look at the common words in each cuisine (see most overlapping words too)\n",
        "* LDA\n",
        "* K-means\n",
        "* A number of words occur only one, what to do about these words?\n",
        "* Choice of features (run evaluation)/different subsets - on subset\n",
        "* Model hyper-paramters (run grid-search) - on subset\n",
        "\n",
        "## Sanity checks after preprocessing\n",
        "\n",
        "\n",
        "\n",
        "1.   Remove Empty recepies: Done\n",
        "2.   Remove Recepies with one or two ingredients: Done\n",
        "4.   Join words like: Olive oil -> Olive_oil: TODO\n",
        "5.   Join words like: warm water, cold water, lukewarm water, boiling water, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSY-CK3ncCqS",
        "colab_type": "text"
      },
      "source": [
        "Let us analyse the dictionary of characters that are present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRMcR9fDL1O3",
        "colab_type": "text"
      },
      "source": [
        "* Token/lemmatizing/capitalization, synonym identification, accented characters and number of ingredients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2s-DO5M-vHV",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWH2oN3v-x2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_test_data(train_data_df, test_data_df):\n",
        "  train_recepies = [] \n",
        "  train_targets = []\n",
        "  for ig_item in train_data_df['ingredients']:\n",
        "      train_recepies.append(ig_item)\n",
        "  for cuisine_item in train_data_df['cuisine']:\n",
        "      train_targets.append(cuisine_item)\n",
        "\n",
        "  # create test data only, no targets\n",
        "  test_recepies = []\n",
        "  for ig_item in test_data_df['ingredients']:\n",
        "      test_recepies.append(ig_item)\n",
        "  return train_recepies, train_targets, test_recepies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmaOocmd_6sI",
        "colab_type": "code",
        "outputId": "18c6aae3-39c2-4e2b-9fc9-89c24533ad12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_features, train_targets, test_features = create_train_test_data(train_data_df, test_data_df)\n",
        "print(train_targets[0:5])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['greek', 'southern_us', 'filipino', 'indian', 'indian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poPcpASERePE",
        "colab_type": "text"
      },
      "source": [
        "#### Remove small receipies, special characters, quantity classifiers (inch, oz etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwDtfaw4cfZL",
        "colab_type": "code",
        "outputId": "b6b3012e-6d89-4aa9-c0dc-fd1c584d05b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "def process_features(features, targets, mode=\"train\"):\n",
        "    processed_recipe = []\n",
        "    processed_cuisine = []\n",
        "    count_len = 0\n",
        "\n",
        "    for idx, recipe in enumerate(features):\n",
        "        processed_ingredient = []\n",
        "        if mode=='train':\n",
        "            cuisine_lower = targets[idx].lower()\n",
        "\n",
        "        # Remove certain words\n",
        "        cur_features = {}\n",
        "        ingredient_all = ' '.join(recipe)\n",
        "\n",
        "        # f1) Add feature for number of ingredients\n",
        "        if len(recipe) <= 2:\n",
        "            count_len += 1\n",
        "            continue\n",
        "        cur_features[\"num_ingredients\"] = len(recipe)\n",
        "\n",
        "        # f2) Change accented characters to ascii characters\n",
        "        accented_char_set= [\"â\", \"ç\", \"è\", \"é\", \"í\", \"î\", \"ú\", \"’\"]\n",
        "        cur_features[\"accented\"] = 0\n",
        "        if 1 in [c in ingredient_all for c in accented_char_set]:\n",
        "            cur_features[\"accented\"] = 1\n",
        "\n",
        "        # f3) Add feature for measurement units\n",
        "        measurement_words = [\"pound\", \"kg\", \"lb\", \"oz\", \"ounc\", \"inch\"]\n",
        "        cur_features[\"measurement\"] = 0\n",
        "        if np.any([w in ingredient_all for w in measurement_words]):\n",
        "            cur_features[\"measurement\"] = 1\n",
        "\n",
        "        # f4) Symbols\n",
        "        cur_features[\"symbol\"] = 0\n",
        "        if (\"™\" in ingredient_all) or (\"®\" in ingredient_all) or (\"!\" in ingredient_all):\n",
        "            cur_features[\"symbol\"] = 1\n",
        "\n",
        "        # f5) Feature for numbers\n",
        "        cur_features[\"number\"] = 0\n",
        "        if any(char.isdigit() for char in ingredient_all):\n",
        "            cur_features[\"number\"] = 1\n",
        "            \n",
        "        # f5) Feature for percentage\n",
        "        cur_features[\"percentage\"] = 0\n",
        "        if \"%\" in ingredient_all:\n",
        "            cur_features[\"percentage\"] = 1\n",
        "\n",
        "        # p1) Convert to lower case\n",
        "        ingredient_all = ingredient_all.lower()\n",
        "        # p2) Change accented characters to ascii characters\n",
        "        ingredient_all = unicodedata.normalize('NFD', ingredient_all).encode('ascii', 'ignore')\n",
        "        ingredient_all = ingredient_all.decode('ascii')\n",
        "        # p3) Remove measurement units\n",
        "        ingredient_all = re.sub((r'\\b(pound|kg|lb|oz|ounc|inch)\\b'), ' ', ingredient_all) \n",
        "        # p4) Remove symbol\n",
        "        ingredient_all = ingredient_all.replace(\"!\", \" \")\n",
        "        ingredient_all = ingredient_all.replace(\"™\", \" \")\n",
        "        ingredient_all = ingredient_all.replace(\"®\", \" \")\n",
        "        # p5) Remove brackets\n",
        "        ingredient_all = ingredient_all.replace(\"(\", \" \")\n",
        "        ingredient_all = ingredient_all.replace(\")\", \" \")\n",
        "        # p6) Remove hyphens\n",
        "        ingredient_all = ingredient_all.replace(\"-\", \" \")\n",
        "        # p7) Remove numbers\n",
        "        ingredient_all = re.sub(\"\\d\", \" \", ingredient_all)\n",
        "        # p8) Remove percentages and / (occur with numbers)\n",
        "        ingredient_all = ingredient_all.replace(\"/\", \" \")\n",
        "        ingredient_all = ingredient_all.replace(\"%\", \" \")\n",
        "\n",
        "        # p9) Remove some more characters\n",
        "        ingredient_all = ingredient_all.replace(\".\", \" \")\n",
        "        ingredient_all = ingredient_all.replace(\"€\", \" \")\n",
        "        ingredient_all = ingredient_all.replace(\",\", \" \")\n",
        "\n",
        "        # p10) Handle apostrophe\n",
        "        ingredient_all = ingredient_all.replace(\"’\", \"'\")\n",
        "        ingredient_all = ingredient_all.replace(\"'\", \"\")\n",
        "\n",
        "        # p11) Replace & with and\n",
        "        ingredient_all = ingredient_all.replace(\"&\", \"and\")\n",
        "\n",
        "        ings = ' '.join(ingredient_all.split())\n",
        "        cur_features[\"num_words\"] = len(ingredient_all.split())\n",
        "\n",
        "        processed_recipe.append((\n",
        "                cur_features[\"num_words\"], cur_features[\"num_ingredients\"],\n",
        "                cur_features[\"accented\"], cur_features[\"measurement\"],\n",
        "                cur_features[\"symbol\"], cur_features[\"number\"],\n",
        "                cur_features[\"percentage\"], ings\n",
        "            ))\n",
        "        if mode=='train':\n",
        "            processed_cuisine.append(cuisine_lower)\n",
        "    \n",
        "    print('Removed {} small recipe from input data'.format(count_len))\n",
        "    if mode=='train':\n",
        "        return processed_recipe, processed_cuisine\n",
        "    else:\n",
        "        return processed_recipe\n",
        "\n",
        "processed_train_features, processed_train_target = process_features(train_features, train_targets, mode='train')\n",
        "processed_test_features = process_features(test_features, train_targets,  mode='test') # just passing the targets, not using it while preprocessing test data\n",
        "\n",
        "\n",
        "print('Sanity check --------------')\n",
        "print(len(processed_train_target))\n",
        "print(len(processed_train_features))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed 215 small recipe from input data\n",
            "Removed 56 small recipe from input data\n",
            "Sanity check --------------\n",
            "39559\n",
            "39559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0KuUyO43cHv",
        "colab_type": "code",
        "outputId": "a145868c-032d-4ae0-f80e-c117f05d9d2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The only characters that remain in representation are characters\n",
        "txt = []\n",
        "for i in range(len(processed_train_features)):\n",
        "    txt.append(processed_train_features[i][-1])\n",
        "print(' '.join(sorted(set(' '.join(txt)))))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  a b c d e f g h i j k l m n o p q r s t u v w x y z\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv9k_ToqE3FD",
        "colab_type": "code",
        "outputId": "23c4c5f3-d040-418a-9465-9a60b71cefe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data = pd.DataFrame(processed_train_features)\n",
        "test_data = pd.DataFrame(processed_test_features)\n",
        "\n",
        "train_data.columns = [\"num_words\", \"num_ingredients\", \"accented\", \"measurement\", \"symbol\", \"number\", \"percentage\", \"text\"]\n",
        "print(train_data.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(39559, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kXyGEczRRjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "bd000388-ceca-4849-8094-05e8de9f608a"
      },
      "source": [
        "train_data.describe()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_ingredients</th>\n",
              "      <th>accented</th>\n",
              "      <th>measurement</th>\n",
              "      <th>symbol</th>\n",
              "      <th>number</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>39559.000000</td>\n",
              "      <td>39559.000000</td>\n",
              "      <td>39559.000000</td>\n",
              "      <td>39559.000000</td>\n",
              "      <td>39559.000000</td>\n",
              "      <td>39559.00000</td>\n",
              "      <td>39559.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20.673955</td>\n",
              "      <td>10.815921</td>\n",
              "      <td>0.014586</td>\n",
              "      <td>0.084709</td>\n",
              "      <td>0.004651</td>\n",
              "      <td>0.00905</td>\n",
              "      <td>0.007938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.919131</td>\n",
              "      <td>4.392268</td>\n",
              "      <td>0.119889</td>\n",
              "      <td>0.278452</td>\n",
              "      <td>0.068042</td>\n",
              "      <td>0.09470</td>\n",
              "      <td>0.088740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>141.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          num_words  num_ingredients  ...       number    percentage\n",
              "count  39559.000000     39559.000000  ...  39559.00000  39559.000000\n",
              "mean      20.673955        10.815921  ...      0.00905      0.007938\n",
              "std        8.919131         4.392268  ...      0.09470      0.088740\n",
              "min        3.000000         3.000000  ...      0.00000      0.000000\n",
              "25%       14.000000         8.000000  ...      0.00000      0.000000\n",
              "50%       20.000000        10.000000  ...      0.00000      0.000000\n",
              "75%       26.000000        13.000000  ...      0.00000      0.000000\n",
              "max      141.000000        65.000000  ...      1.00000      1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGIZrd1ZR30H",
        "colab_type": "text"
      },
      "source": [
        "## Feature engineering: Binarize textual recepies/features\n",
        "\n",
        "max_df = 0.99 -> remove any word which is occuring in more than 99% of the sample\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzLK5VWaHqm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# strip_accents uses ascii\n",
        "def generate_one_hot_vec(train_bin_vec, test_bin_vec):\n",
        "  binarizer = CountVectorizer(analyzer = \"word\",  ngram_range = (1,2), \n",
        "                              binary = False, tokenizer = None, preprocessor = None, \n",
        "                              stop_words = None,  min_df=0.01) \n",
        "  binarizer.fit([str(i) for i in train_bin_vec])\n",
        "  print(len(train_bin_vec))\n",
        "  binary_vector_tr = binarizer.transform([str(i) for i in train_bin_vec])\n",
        "  binary_vector_te = binarizer.transform([str(i) for i in test_bin_vec])\n",
        "  return binary_vector_tr, binary_vector_te, binarizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q3rJCExSEtS",
        "colab_type": "code",
        "outputId": "ccf8cf35-6280-4ce6-f5d9-2b4caffbbce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_rep1, test_rep1, binarizer = generate_one_hot_vec(processed_train_features, processed_test_features)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WFzz_80NcJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47b2e06f-4f08-4de9-a2e7-70b747924365"
      },
      "source": [
        "print(list(binarizer.vocabulary_.keys())[0:10])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['16', 'lettuce', 'black', 'olives', 'tomatoes', 'garlic', 'pepper', 'purple', 'onion', 'seasoning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMUUnoaBSLvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss, accuracy_score \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "def train(train_binary_vector, processed_train_target):\n",
        "  lb_en = LabelEncoder()\n",
        "  processed_train_target_encoded = lb_en.fit_transform(processed_train_target)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(train_binary_vector, processed_train_target_encoded , random_state = 0)\n",
        "  classifiers = []\n",
        "\n",
        "  log_reg = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
        "  random_fc = RandomForestClassifier(n_estimators=20, random_state=42)\n",
        "  svm_mod = SVC(C=0.01,  probability=True)\n",
        "\n",
        "  classifiers = {\"Logistic\" :log_reg, \"Random_Forest\": random_fc,}\n",
        "                #  \"SVM\": svm_mod}\n",
        "\n",
        "  for cl in classifiers:\n",
        "    print(cl)u\n",
        "    mod = classifiers[cl]\n",
        "    mod.fit(X_train, y_train)\n",
        "    scores = cross_val_score(mod, X_train, y_train, cv=5)\n",
        "    print(scores)\n",
        "    print(np.mean(scores))\n",
        "    print(\"-----\")\n",
        "    # # print('RFC LogLoss {score}'.format(score=log_loss(y_test, mod.predict_proba(X_test))))\n",
        "    # print('RFC Accuracy {score}'.format(score=accuracy_score(y_test, mod.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CodWLa8OXF60",
        "colab_type": "code",
        "outputId": "55b34d96-bd22-426d-c5f8-dac543f9c97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "train(train_rep1, processed_train_target)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic\n",
            "[0.71594545 0.71577707 0.73247978 0.72360877 0.71864979]\n",
            "0.7212921709149775\n",
            "-----\n",
            "Random_Forest\n",
            "[0.70247516 0.6896784  0.69946092 0.69763912 0.69367089]\n",
            "0.696584897365291\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ti70uYvc0Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}